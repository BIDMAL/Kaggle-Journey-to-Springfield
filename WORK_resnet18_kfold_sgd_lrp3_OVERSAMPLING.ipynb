{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchsummary\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MODES = ['train', 'val', 'test']\n",
    "RESCALE_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "EPOCHS=30\n",
    "BATCH_SIZE=64\n",
    "N_FOLDS = 2\n",
    "\n",
    "SEED = 69\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "     \n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                  pickle.dump(self.label_encoder, le_dump_file)\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "      \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        transform_list = []\n",
    "        transform_list.append(transforms.Resize((RESCALE_SIZE, RESCALE_SIZE)))\n",
    "        if self.mode != 'test':            \n",
    "            transform_list.append(transforms.RandomHorizontalFlip())\n",
    "            transform_list.append(transforms.RandomRotation(15))\n",
    "        transform_list.append(transforms.ToTensor())\n",
    "        transform_list.append(transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "        \n",
    "        transform = transforms.Compose(transform_list)\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dct_path_labels(train_val_files, train_val_labels):\n",
    "    dct_simpsons = {}\n",
    "    for label_i in np.unique(train_val_labels).tolist():\n",
    "        dct_simpsons[label_i] = []\n",
    "\n",
    "    for path_i, label_i in zip(train_val_files, train_val_labels):\n",
    "        dct_simpsons[label_i].append(path_i)\n",
    "\n",
    "    return dct_simpsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path('train/simpsons_dataset')\n",
    "TEST_DIR = Path('testset/testset')\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "\n",
    "dct_train_val = {}\n",
    "dct_train_val = create_dct_path_labels(train_val_files, train_val_labels)\n",
    "\n",
    "#dct_simpsons_wht = {}\n",
    "#for key in dct_train_val:\n",
    "#    dct_simpsons_wht.update({key:1. / dct_train_val[key]})\n",
    "    \n",
    "train_val_dataset = SimpsonsDataset(train_val_files, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b71678fc150f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWeightedRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-b71678fc150f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWeightedRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "class_counts = [len(dct_train_val[char]) for char in dct_train_val]\n",
    "num_samples = sum(class_counts)\n",
    "labels = train_val_labels\n",
    "\n",
    "class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'abraham_grampa_simpson',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'agnes_skinner',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'apu_nahasapeemapetilon',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def eval_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_size += inputs.size(0)\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.double() / processed_size\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def train(train_files, val_files, model, epochs, batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        opt = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            opt, mode='max', factor=0.1, patience=3, verbose=False)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
    "            print(\"loss\", train_loss)            \n",
    "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "            history.append((train_loss, train_acc, val_loss, val_acc))            \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "            scheduler.step(val_acc)\n",
    "                \n",
    "    return history\n",
    "\n",
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "    \n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            \n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 42]          21,546\n",
      "================================================================\n",
      "Total params: 11,198,058\n",
      "Trainable params: 21,546\n",
      "Non-trainable params: 11,176,512\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.72\n",
      "Estimated Total Size (MB): 106.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(train_val_labels))\n",
    "clf = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in clf.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "clf.fc = nn.Linear(in_features=clf.fc.in_features, out_features=n_classes)\n",
    "clf = clf.to('cuda')\n",
    "torchsummary.summary(clf.cuda(), (3, RESCALE_SIZE, RESCALE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "\n",
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "submit = pd.DataFrame(columns=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch:   0%|                                                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.4294599394121565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   3%|██▌                                                                         | 1/30 [01:36<46:38, 96.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001 train_loss: 2.4295     val_loss 1.3821 train_acc 0.4343 val_acc 0.7064\n",
      "loss 0.8392718569442383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   7%|█████                                                                       | 2/30 [03:12<44:56, 96.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 002 train_loss: 0.8393     val_loss 0.5856 train_acc 0.7930 val_acc 0.8477\n",
      "loss 0.4372842376621922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  10%|███████▌                                                                    | 3/30 [04:48<43:18, 96.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 003 train_loss: 0.4373     val_loss 0.4551 train_acc 0.8850 val_acc 0.8758\n",
      "loss 0.2658645382427945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  13%|██████████▏                                                                 | 4/30 [06:24<41:37, 96.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 004 train_loss: 0.2659     val_loss 0.3237 train_acc 0.9292 val_acc 0.9174\n",
      "loss 0.20451155109912292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  17%|████████████▋                                                               | 5/30 [08:00<40:01, 96.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 005 train_loss: 0.2045     val_loss 0.2600 train_acc 0.9486 val_acc 0.9361\n",
      "loss 0.16382816309038012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  20%|███████████████▏                                                            | 6/30 [09:46<39:36, 99.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 006 train_loss: 0.1638     val_loss 0.2580 train_acc 0.9553 val_acc 0.9355\n",
      "loss 0.11937967677223914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  23%|█████████████████▋                                                          | 7/30 [11:24<37:51, 98.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 007 train_loss: 0.1194     val_loss 0.2540 train_acc 0.9716 val_acc 0.9400\n",
      "loss 0.10031587152823467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  27%|████████████████████▎                                                       | 8/30 [12:59<35:52, 97.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 008 train_loss: 0.1003     val_loss 0.2687 train_acc 0.9728 val_acc 0.9381\n",
      "loss 0.07870381493177556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  30%|██████████████████████▊                                                     | 9/30 [14:35<34:00, 97.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 009 train_loss: 0.0787     val_loss 0.2373 train_acc 0.9785 val_acc 0.9450\n",
      "loss 0.07410244269797465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  33%|█████████████████████████                                                  | 10/30 [16:11<32:17, 96.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 010 train_loss: 0.0741     val_loss 0.2157 train_acc 0.9815 val_acc 0.9487\n",
      "loss 0.05912317270720276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  37%|███████████████████████████▍                                               | 11/30 [17:48<30:38, 96.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 011 train_loss: 0.0591     val_loss 0.2207 train_acc 0.9834 val_acc 0.9497\n",
      "loss 0.044985467790083264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  40%|██████████████████████████████                                             | 12/30 [19:31<29:38, 98.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 012 train_loss: 0.0450     val_loss 0.2242 train_acc 0.9869 val_acc 0.9500\n",
      "loss 0.03633657052539705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  43%|████████████████████████████████▌                                          | 13/30 [21:09<27:55, 98.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 013 train_loss: 0.0363     val_loss 0.2407 train_acc 0.9911 val_acc 0.9520\n",
      "loss 0.03490599733073086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  47%|███████████████████████████████████                                        | 14/30 [22:46<26:07, 97.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 014 train_loss: 0.0349     val_loss 0.2474 train_acc 0.9903 val_acc 0.9459\n",
      "loss 0.020836942953319802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  50%|█████████████████████████████████████▌                                     | 15/30 [24:22<24:21, 97.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 015 train_loss: 0.0208     val_loss 0.2286 train_acc 0.9939 val_acc 0.9503\n",
      "loss 0.02576659225249299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  53%|████████████████████████████████████████                                   | 16/30 [25:59<22:40, 97.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 016 train_loss: 0.0258     val_loss 0.2511 train_acc 0.9927 val_acc 0.9507\n",
      "loss 0.026922702180283125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  57%|██████████████████████████████████████████▌                                | 17/30 [27:41<21:23, 98.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 017 train_loss: 0.0269     val_loss 0.2426 train_acc 0.9930 val_acc 0.9531\n",
      "loss 0.019858522379293767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  60%|█████████████████████████████████████████████                              | 18/30 [29:17<19:36, 98.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 018 train_loss: 0.0199     val_loss 0.2661 train_acc 0.9942 val_acc 0.9440\n",
      "loss 0.01889938333385046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  63%|███████████████████████████████████████████████▌                           | 19/30 [30:54<17:52, 97.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 019 train_loss: 0.0189     val_loss 0.2429 train_acc 0.9952 val_acc 0.9522\n",
      "loss 0.01668679412363473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  67%|██████████████████████████████████████████████████                         | 20/30 [32:30<16:11, 97.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 020 train_loss: 0.0167     val_loss 0.2486 train_acc 0.9952 val_acc 0.9504\n",
      "loss 0.014084467385891891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  70%|████████████████████████████████████████████████████▌                      | 21/30 [34:07<14:33, 97.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 021 train_loss: 0.0141     val_loss 0.2107 train_acc 0.9959 val_acc 0.9580\n",
      "loss 0.010936618624068677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  73%|██████████████████████████████████████████████████████▉                    | 22/30 [35:43<12:55, 96.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 022 train_loss: 0.0109     val_loss 0.2367 train_acc 0.9973 val_acc 0.9602\n",
      "loss 0.006235723922854332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  77%|█████████████████████████████████████████████████████████▌                 | 23/30 [37:20<11:17, 96.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 023 train_loss: 0.0062     val_loss 0.2543 train_acc 0.9981 val_acc 0.9535\n",
      "loss 0.010602070405905845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  80%|████████████████████████████████████████████████████████████               | 24/30 [38:56<09:40, 96.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 024 train_loss: 0.0106     val_loss 0.2548 train_acc 0.9964 val_acc 0.9541\n",
      "loss 0.012766633533573855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  83%|██████████████████████████████████████████████████████████████▌            | 25/30 [40:32<08:02, 96.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 025 train_loss: 0.0128     val_loss 0.2719 train_acc 0.9970 val_acc 0.9499\n",
      "loss 0.008251316290436258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  87%|█████████████████████████████████████████████████████████████████          | 26/30 [42:09<06:25, 96.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 026 train_loss: 0.0083     val_loss 0.2457 train_acc 0.9977 val_acc 0.9577\n",
      "loss 0.0035583320400622365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 27/30 [43:45<04:49, 96.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 027 train_loss: 0.0036     val_loss 0.2233 train_acc 0.9990 val_acc 0.9633\n",
      "loss 0.0021367395946852155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  93%|██████████████████████████████████████████████████████████████████████     | 28/30 [45:21<03:12, 96.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 028 train_loss: 0.0021     val_loss 0.2206 train_acc 0.9994 val_acc 0.9623\n",
      "loss 0.0016557070712936502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  97%|████████████████████████████████████████████████████████████████████████▌  | 29/30 [46:58<01:36, 96.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 029 train_loss: 0.0017     val_loss 0.2230 train_acc 0.9997 val_acc 0.9625\n",
      "loss 0.001538245778419857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|███████████████████████████████████████████████████████████████████████████| 30/30 [48:34<00:00, 97.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 030 train_loss: 0.0015     val_loss 0.2174 train_acc 0.9997 val_acc 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_val_files, label_encoder.transform(train_val_labels))):\n",
    "    print('\\nFOLD', fold+1)\n",
    "    val_dataset = SimpsonsDataset(np.array(train_val_files)[val_idx], mode='val')\n",
    "    train_dataset = SimpsonsDataset(np.array(train_val_files)[train_idx], mode='train')\n",
    "    \n",
    "    clf = models.resnet18(pretrained=True)\n",
    "    clf.fc = nn.Linear(in_features=clf.fc.in_features, out_features=n_classes)\n",
    "    clf = clf.to('cuda')\n",
    "        \n",
    "    history = train(train_dataset, val_dataset, model=clf, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    loss, acc, val_loss, val_acc = zip(*history)\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    plt.plot(loss, label=\"train_loss\")\n",
    "    plt.plot(val_loss, label=\"val_loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    probs = predict(clf, test_loader)\n",
    "    preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))    \n",
    "    submit[f'fold_{fold+1}'] = preds    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>fold_1</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img0.jpg</td>\n",
       "      <td>nelson_muntz</td>\n",
       "      <td>img0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img10.jpg</td>\n",
       "      <td>ned_flanders</td>\n",
       "      <td>img10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img100.jpg</td>\n",
       "      <td>chief_wiggum</td>\n",
       "      <td>chief_wiggum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img101.jpg</td>\n",
       "      <td>apu_nahasapeemapetilon</td>\n",
       "      <td>apu_nahasapeemapetilon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                  fold_1                Expected\n",
       "0    img0.jpg            nelson_muntz                img0.jpg\n",
       "1    img1.jpg            bart_simpson            bart_simpson\n",
       "2   img10.jpg            ned_flanders               img10.jpg\n",
       "3  img100.jpg            chief_wiggum            chief_wiggum\n",
       "4  img101.jpg  apu_nahasapeemapetilon  apu_nahasapeemapetilon"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filenames = [path.name for path in test_dataset.files]\n",
    "submit['Id'] = test_filenames\n",
    "submit['Expected'] = submit.mode(axis=1)[0]\n",
    "submit[['Id', 'Expected']].to_csv('submission_resnet18_sgd_lrp3.csv', index=False)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bite09425d6ee09468da8ea42744a60d97e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
